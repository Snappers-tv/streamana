<html>
<head>
<!-- These import maps enable import of glsl-canvas without a bunder.
     In production you probably want to use a bundler with resource integrity. -->
<script type="importmap">
{
  "imports": {
    "glsl-canvas-js": "https://unpkg.com/glsl-canvas-js@0.2.6/dist/esm/glsl.js",
    "promise-polyfill": "https://unpkg.com/promise-polyfill@8.2.0/src/index.js",
    "gl-matrix": "https://unpkg.com/gl-matrix@3.3.0/esm/index.js"
  }
}
</script>
<script type="module">
import { InvisibleGlCanvas } from './gl-canvas.js';
import { HlsWorker } from './hls-worker.js';

let stream_url_el, start_el, stop_el, monitor_el;
let camera_stream, gl_canvas, canvas_stream, recorder, hls_worker;

async function start() {
  const stream_url = stream_url_el.value.trim();
  if (!stream_url) {
    return;
  }
  localStorage.setItem('streamana-example-streamurl', stream_url);

  start_el.disabled = true;

  // capture video from webcam
  camera_stream = await navigator.mediaDevices.getUserMedia({
    audio: true,
    video: {
      width: 4096,
      height: 2160,
      frameRate: {
        ideal: 30,
        max: 30
      }
    }
  });

  // create video element which will be used for grabbing the frames to
  // write to a canvas so we can apply webgl shaders
  // also used to get the native video dimensions
  const video = document.createElement("video");
  video.muted = true;

  // use glsl-canvas to make managing webgl stuff easier
  // because it's not visible, client dimensions are zero so we
  // need to substitute actual dimensions instead
  gl_canvas = new InvisibleGlCanvas(document);

  // sample greyscale fragment shader
  const fragmentShader = `
precision highp float;

uniform sampler2D u_texture;
uniform vec2 u_resolution;

void main() {
  vec2 st = gl_FragCoord.xy / u_resolution.xy;
  vec3 color = texture2D(u_texture, st).rgb;
  float grey = dot(color, vec3(0.299, 0.587, 0.114));
  gl_FragColor = vec4(vec3(grey), 1.0);
}`;
  gl_canvas.load(fragmentShader);

  // tell canvas to use frames from video
  gl_canvas.setTexture('u_texture', video);

  // wait for video to load (must come after gl_canvas.setTexture() since it
  // registers a loadeddata handler which then registers a play handler)
  video.addEventListener('loadeddata', function () {
    // make canvas same size as native video dimensions so every pixel is seen
    gl_canvas.canvas.width = this.videoWidth;
    gl_canvas.canvas.height = this.videoHeight;

    // start the camera video
    this.play();

    // capture video from the canvas
    canvas_stream = gl_canvas.canvas.captureStream(30);
    canvas_stream.addTrack(camera_stream.getAudioTracks()[0]);

    // set up video recording from the canvas; note we don't start
    // recording until ffmpeg has started (below)
    recorder = new MediaRecorder(canvas_stream, {
      mimeType: "video/webm;codecs=H264",
      audioBitsPerSecond:  128 * 1000,
      videoBitsPerSecond: 2500 * 1000
    });

    // push encoded data into the ffmpeg worker that we start below
    recorder.ondataavailable = async function (event) {
      hls_worker.write(await event.data.arrayBuffer());
    };

    // start ffmpeg in a worker
    hls_worker = new HlsWorker(stream_url);
    hls_worker.addEventListener('run', () => console.log("HLS running"));
    hls_worker.addEventListener('exit', ev => {
      console.log("HLS exited with code", ev.detail);
      if (recorder.state !== 'inactive') {
        recorder.stop();
      }
      monitor_el.srcObject = null;
      start_el.disabled = false;
    });
    hls_worker.addEventListener('error', ev => {
      console.error("HLS errored", ev.detail);
    });
    hls_worker.addEventListener('abort', ev => {
      console.error("HLS aborted", ev.detail);
    });
    hls_worker.addEventListener('start-video', () => {
      // start recording; produce data every second, we'll be chunking it anyway
      recorder.start(1000);
    });

    // display the video locally so we can see what's going on
    // note the video seems to set its height automatically to keep the
    // correct aspect ratio
    monitor_el.srcObject = canvas_stream;
    monitor_el.play();

    stop_el.disabled = false;
  });

  // pass the stream from the camera to the video so it can render the frames
  video.srcObject = camera_stream;
}

function stop() {
  stop_el.disabled = true;

  for (let track of camera_stream.getTracks()) {
    track.stop();
  }

  gl_canvas.destroy();

  for (let track of canvas_stream.getTracks()) {
    track.stop();
  }
  
  hls_worker.end();
}

window.addEventListener('load', function () {
  stream_url_el = document.getElementById('stream_url');
  start_el = document.getElementById('start');
  stop_el = document.getElementById('stop');
  monitor_el = document.getElementById('monitor');
  stream_url.value = localStorage.getItem('streamana-example-streamurl');
  start_el.disabled = false;

  start_el.addEventListener('click', start);
  stop_el.addEventListener('click', stop);
});
</script>
</head>
<body>
<p>
  <input id=stream_url type="text" placeholder="Youtube Stream URL">
  <input id=start type="button" value="Start" disabled>
  <input id=stop type="button" value="Stop" disabled>
</p>
<video id="monitor" style="width:100%" muted="true"></video>
</body>
</html>
